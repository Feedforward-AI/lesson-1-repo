# PROPOSAL

## Meridian AI Lab: Building the Future Today

**Submitted by:** Jordan Torres, Head of AI Initiative  
**Date:** September 28, 2025  
**Version:** 2.1

---

## Executive Summary

I'm proposing we create a dedicated AI Lab: a small team of high performers with access to frontier AI tools and a mandate to experiment, learn, and spread knowledge across Meridian.

This isn't about replacing our current approach. It's about creating a parallel track where we can move faster, learn more, and develop the organizational muscle we'll need as AI capabilities accelerate.

**Investment ask:** $400K incremental annual cost (personnel reallocation + tools + infrastructure)

**Team:** 8 high performers from across the organization + 2 AI-capable developers

**Timeline:** 12-month initial commitment with quarterly reviews

---

## The Problem We're Solving

We're stuck.

Our current approach—enterprise-wide deployment of a "safe" tool (EnterpriseAI.ai) with extensive governance—has produced:
- 12% adoption
- Minimal workflow transformation
- Growing frustration from our most capable people
- Zero competitive advantage

Meanwhile, the technology is advancing faster than our evaluation process. By the time we approve a tool, it's already a generation behind.

I've talked to dozens of employees across Meridian. The consistent theme: "I want to use AI, but the tools we're given aren't good enough, and the tools I want to use aren't allowed."

We've created a system optimized for risk avoidance that's actually generating a different kind of risk: the risk of falling behind.

---

## The Proposal

### What

A dedicated team of 10 people, working with frontier AI tools, tasked with:

1. **Discovering** high-value AI applications across Meridian's functions
2. **Developing** prototypes and proof-of-concept implementations
3. **Documenting** what works, what doesn't, and why
4. **Disseminating** knowledge across the organization
5. **De-risking** future enterprise deployments by learning in a contained environment

### Who

**8 "Star Performers"** selected from across the organization:
- Production/Operations
- Marketing
- Supply Chain
- Finance
- Legal Operations
- Customer Insights
- R&D/Innovation
- HR/Talent
- Sales Operations

Selection criteria:
- Demonstrated high performance in current role
- Curiosity and willingness to experiment
- Ability to communicate learnings to non-technical colleagues
- Diverse perspectives (we want different mental models, not eight of the same person)

**2 AI-Capable Developers:**
- Technical support for the star performers
- Build custom integrations and tools
- Bridge between experimentation and production deployment

### Why These People

The star performers aren't leaving their roles entirely—this is 50-60% of their time, with their regular work backfilled or redistributed. The idea is:

1. They bring deep domain expertise (they know where AI would actually help)
2. They stay connected to real work (not a skunkworks that loses touch)
3. They become internal evangelists (their peers trust them)
4. They carry knowledge back when the Lab's work is done

### What Tools

The Lab gets access to:
- Frontier models (Claude, GPT-4, Gemini) via API
- Coding assistants (Cursor, GitHub Copilot, Claude Code)
- Workflow automation tools (n8n, Zapier, custom pipelines)
- Data analysis tools appropriate to their function
- Experimental tools as they emerge (with Security's input, not sign-off)

This is the key difference from current approach: we're giving capable people capable tools, rather than giving everyone limited tools.

### Governance

Yes, there's governance. But it's designed for speed:

- **Clear bright lines:** No PII. No customer data without consent. No external distribution without review.
- **Weekly check-ins:** Security and Legal have visibility, not veto power
- **Monthly steering committee updates:** Course correction as needed
- **Incident protocol:** If something goes wrong, we pause and assess

The Lab is a contained experiment. If we break something, we break it in a controlled environment with our most capable people, not across 8,000 employees.

---

## What the Lab Will Produce

Quarterly deliverables:

1. **Use case library:** Documented examples of high-value AI applications
2. **Failure analysis:** What we tried that didn't work, and why
3. **Deployment recommendations:** Which applications are ready for broader rollout
4. **Capability assessment:** What the current frontier can and can't do
5. **Training materials:** For scaling knowledge to the rest of the organization

---

## Investment

| Category | Annual Cost |
|----------|-------------|
| Star performer backfill (partial) | $180K |
| 2 FTE developers | $280K |
| Tool access (API costs, licenses) | $120K |
| Infrastructure | $40K |
| Training and development | $30K |
| **Total incremental** | **$650K** |
| Less: existing budget reallocation | ($250K) |
| **Net new investment** | **$400K** |

Note: This assumes we reduce EnterpriseAI.ai licenses from 2,000 to 500 (covering employees who actually use it), saving $540K annually. If we net that against the Lab investment, we're actually reducing total AI spend while increasing capability.

---

## Risks and Mitigations

| Risk | Mitigation |
|------|------------|
| Security incident | Contained environment, capable users, clear protocols |
| Lab becomes ivory tower | 50% time in regular role; regular knowledge sharing |
| Star performers don't return | Career development commitment; Lab alumni network |
| No measurable impact | Quarterly milestones; fail-fast approach |
| Resentment from non-selected employees | Transparent selection; Lab serves the whole org |

---

## Success Metrics

After 12 months, we should be able to answer:

1. How many high-value AI use cases did we discover?
2. How many were deployed beyond the Lab?
3. What measurable impact did those deployments have?
4. How much faster did we move compared to our current process?
5. How did Lab participants' capabilities grow?

I'm proposing quarterly milestones so we can course-correct, not waiting until month 12 to find out if it worked.

---

## Why Now

The gap between frontier AI capabilities and our deployed tools is widening, not closing. Every quarter we wait:

- Frontier models get more capable
- Our competitors build more organizational muscle
- Our best people get more frustrated
- The eventual catch-up cost increases

The Lab isn't about going faster for its own sake. It's about building the absorptive capacity we'll need when AI capabilities cross the threshold into genuine transformation. By the time that's obvious to everyone, it'll be too late to start.

---

## The Ask

I'm asking for:

1. Approval to form the Lab with the investment outlined above
2. Authority to select participants with input from their managers
3. Governance model as described (Security and Legal visibility, not veto)
4. 12-month commitment with quarterly reviews
5. Executive sponsor (I'd suggest Carla directly, given the cross-functional nature)

I believe this is the highest-leverage investment Meridian can make in 2026. I'm happy to answer questions and refine the proposal based on feedback.

Jordan Torres
