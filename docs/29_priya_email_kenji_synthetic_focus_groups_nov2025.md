# EMAIL

**From:** Priya Sharma <psharma@meridian.com>
**To:** Jordan Torres <jtorres@meridian.com>
**Date:** November 19, 2025 2:14 PM
**Subject:** What my associate just did with AI customer research

---

Jordan,

I have to tell you about something one of my people did. It's either brilliant or insane, and I genuinely can't tell which, but the results speak for themselves.

His name is Kenji Okonkwo. 26 years old, Associate Brand Coordinator, been here about 14 months. Came from a small agency, very sharp, maybe too creative for his own good sometimes.

---

Here's the situation. We're launching the ProGuard industrial safety line in Q1. Standard process: we'd run focus groups to test positioning and messaging before we commit to the campaign. Three groups, two cities, six weeks, $42,000 all-in with the research agency.

Kenji comes to me two weeks ago and says: "What if I could get you directionally similar insights in a day for free?"

I said okay, show me.

---

What he built:

He took our customer segmentation data—the personas we developed last year with that expensive consulting project—and fed them into Claude. But not just the demographics. He gave it purchase history patterns, industry context, pain points from our VOC surveys, even language patterns from customer emails.

Then he ran what he calls "synthetic interviews." He'd ask Claude to respond AS one of these personas to our messaging concepts. Not "what would this persona think" but "you are Mike, a 52-year-old plant safety manager in Ohio who's been burned by vendors overpromising. React to this headline."

He ran 50 of these interviews across our four core personas. Took him about 6 hours total, including setup.

---

Here's what he found:

Our planned messaging was centered on cost savings: "ProGuard: Premium Protection, Smart Pricing."

The synthetic customers *hated* it. Or rather, they were skeptical. The AI-as-customer kept raising objections like:
- "When someone says 'smart pricing' I hear 'cheap'"
- "I'm not buying safety equipment to save money, I'm buying it so nobody gets hurt"
- "Cost savings messaging makes me think you cut corners somewhere"

But when Kenji tested a reliability angle—"ProGuard: When Your People Depend On It"—the synthetic responses were dramatically different. Emotional resonance. Trust language. Purchase intent signals.

I was skeptical. This is a machine talking to itself. What does it know about real customers?

---

So we ran a real focus group. One group, 10 people, $8,400. Not to validate the whole campaign, just to gut-check Kenji's findings.

The results:

- "Premium Protection, Smart Pricing": 4 out of 10 said they'd consider it
- "When Your People Depend On It": 7 out of 10, with notably stronger emotional language

The reliability message tested 40% stronger. Exactly what the synthetic interviews predicted.

Kenji's $0, 6-hour test caught a positioning mistake that would have been baked into a multi-million dollar campaign.

---

Now here's the problem.

I mentioned this to Rob (our CMO) and his reaction was... complicated. He's not opposed to innovation, but he's worried about:

1. "Making decisions based on fake data" — what if the AI is just telling us what we want to hear?
2. "What do we tell the board?" — he can't present to leadership and say our campaign strategy was validated by a chatbot
3. "What about the research agency?" — they're a long-term partner and they're already asking why we only did one focus group

Also, Margaret in Legal called me. She's concerned about whether synthetic customer quotes could somehow create liability. I don't even understand the concern, honestly, but she wants to "review the methodology" before we do this again.

So Kenji built something that works—demonstrably works—and now he's being told to pause while people figure out how they feel about it.

---

Here's my back-of-envelope math:

We run 15-20 focus group projects per year. Average cost: $35,000 each. That's $500-700K annually.

If synthetic interviews could replace even HALF of that—or reduce scope so we only do confirmatory research instead of exploratory—we're talking $250-350K in direct savings.

But the real value isn't the cost savings. It's the speed. We could test 10 messaging concepts in a day instead of picking 3 and hoping we got it right. We could iterate on positioning weekly instead of quarterly. We could catch mistakes before they're baked in.

And Kenji figured this out with a $20/month Claude subscription on his personal credit card.

---

I know you're working on the AI Lab proposal. Kenji is exactly the kind of person you're talking about—curious, resourceful, willing to experiment. He's not a data scientist. He's a brand guy who saw a problem and solved it.

But right now he's in limbo. Rob's not saying no, but he's not saying yes. Legal wants a review. The research agency is lobbying to protect their turf. And Kenji is starting to wonder if he made a mistake by showing anyone what he built.

Let me know if you want to talk to him. He's got more ideas—he mentioned something about using AI to generate first-draft creative concepts for A/B testing. But I think he's going to stop sharing them if the response is always "that's interesting, let's form a committee."

Priya

---

**P.S.** — I asked Kenji what made him try this. He said he'd been reading about how movie studios and game companies use AI to test audience reactions before spending millions on production. He figured: if it works for Marvel, why not for industrial safety equipment? Kid thinks different. I don't want to lose him.
